{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc2b7a4-80e3-44c4-8aee-e5dea8dd3dab",
   "metadata": {},
   "source": [
    "## DOCUMENTAÇÃO DAS CLASSES PARA EXTRAÇÃO DE RELAÇÕES TEMPORAIS E TIMEBANKPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b45cf81-8220-4c11-aa69-1f9b28c80468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQUÊNCIA PIPELINE: PORTUGUÊS\n",
      "   1 -> tok2vec\n",
      "   2 -> morphologizer\n",
      "   3 -> parser\n",
      "   4 -> attribute_ruler\n",
      "   5 -> lemmatizer\n",
      "   6 -> ner\n",
      "   7 -> pipe_timebankpt\n",
      "   8 -> merge_entities\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from parse.ParseTimebankPT import TimebankPT, RelacaoTemporal\n",
    "\n",
    "path_tml = r'TimeBankPT\\train\\ABC*.tml'\n",
    "tb = TimebankPT(path_tml)\n",
    "rt = RelacaoTemporal(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42c185-7e59-40ef-ab45-9da1d08e825d",
   "metadata": {},
   "source": [
    "### TimebankPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fa80385-751f-4e4d-9c8d-fbbe3b40897c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m  \u001b[0mTimebankPT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_tml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_timebank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Importa dados dos arquivos do corpus TimebankPT e fornece vários métodos para manipular o conteúdo do corpus.\n",
       "\n",
       "Args:\n",
       "    path_tml: caminho do corpus TimebankPT no formato: 'c:\\diretorio\\*\\*.txt'\n",
       "    add_timebank: adiciona tags (EVENT E TIMEX3) do corpus TimebankPT ao pipeline do spaCy. Default é True\n",
       "    \n",
       "\u001b[1;31mFile:\u001b[0m           e:\\backup_online\\onedrive\\documents\\dárcio online\\pós-graduação\\mestrado\\experimentos\\temporal_relation\\parse\\parsetimebankpt.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? TimebankPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f77d851-cfbc-4a71-8e05-c438d1bfe96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TimebankPT in module parse.ParseTimebankPT object:\n",
      "\n",
      "class TimebankPT(Functions)\n",
      " |  TimebankPT(path_tml, add_timebank=True, lang='pt')\n",
      " |  \n",
      " |  Importa dados dos arquivos do corpus TimebankPT e fornece vários métodos para manipular o conteúdo do corpus.\n",
      " |  \n",
      " |  Args:\n",
      " |      path_tml: caminho do corpus TimebankPT no formato: 'c:\\diretorio\\*\\*.txt'\n",
      " |      add_timebank: adiciona tags (EVENT E TIMEX3) do corpus TimebankPT ao pipeline do spaCy. Default é True\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TimebankPT\n",
      " |      Functions\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, path_tml, add_timebank=True, lang='pt')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Exibe as quantidades dos objetos do TimebankPT\n",
      " |  \n",
      " |  add_pipe_timebank(self)\n",
      " |      Adiciona o pipe que adiciona tags dos timebankPT ao Doc no spaCy\n",
      " |  \n",
      " |  eh_nome_doc(self, nome_doc: str)\n",
      " |      Verifica se o nome_doc pertence aos arquivos do corpus TimeBankPT\n",
      " |      \n",
      " |      Args:\n",
      " |          nome_doc: Nome de arquivo do TimebankPT\n",
      " |  \n",
      " |  get_dct_doc(self, nome_doc=None)\n",
      " |      Retorna lista com Data de Criação do Documento(DCT) da id_sentença setada em set_id_sentenca() ou str da id_sentenca do parametro\n",
      " |      \n",
      " |      Args:\n",
      " |          nome_doc: se informado, sobrepõe as id_sentenca atribuida em set_id_sentenca()\n",
      " |      \n",
      " |      Return:\n",
      " |          lista com DCT.\n",
      " |  \n",
      " |  get_doc(self, id_sentenca=None)\n",
      " |      Retorna lista de objetos Doc do spaCy\n",
      " |      \n",
      " |      Return:\n",
      " |          Lista de Docs\n",
      " |  \n",
      " |  get_doc_root(self, doc: spacy.tokens.doc.Doc = None) -> spacy.tokens.token.Token\n",
      " |      Retorn o root do Doc.\n",
      " |      Se root for pontuação, verificar se não há outro root que não seja pontuação.\n",
      " |  \n",
      " |  get_doc_unico(self)\n",
      " |      Retorna o primeiro Doc da lista de Docs (self.doc).\n",
      " |      \n",
      " |      Return:\n",
      " |          Doc\n",
      " |  \n",
      " |  get_id_sentenca(self, texto_sentenca=None)\n",
      " |      Retorna as id_sentenca setadas em set_id_sentenca() se texto_sentenca não for informado\n",
      " |      \n",
      " |      Se texto_sentenca for informado:      \n",
      " |          Busca a id_sentenca correspondente à texto_sentenca no TimeBankPt, e a retorna.\n",
      " |      \n",
      " |      Args: \n",
      " |          texto_sentenca: Texto da sentença a ser procurada em TimeBankPt\n",
      " |          \n",
      " |      Return:\n",
      " |          list id_sentenca\n",
      " |  \n",
      " |  get_id_sentenca_unica(self)\n",
      " |      Retorna lista com a primeira id_sentenca da lista de senteças setadas em set_id_sentenca()\n",
      " |  \n",
      " |  get_id_sentencas_dep(self)\n",
      " |      Retorna também lista de id_sentenca dependentes da sentenca do documento atual.\n",
      " |  \n",
      " |  get_id_sentencas_doc(self)\n",
      " |      Retorna lista de todas id_sentenca do primeiro documento da lista de documentos atual.\n",
      " |      O nome do documento é o nome do arquivo do TimeBankPT.\n",
      " |  \n",
      " |  get_nome_doc(self, id_sentenca=None)\n",
      " |      Retorna lista com nome do documento da id_sentença setada em set_id_sentenca() ou str da id_setenca do parametro\n",
      " |      \n",
      " |      Args:\n",
      " |          id_sentenca: se informado, sobrepõe id_sentenca atribuido em set_id_sentenca()\n",
      " |      \n",
      " |      Return:\n",
      " |          Nome de documentos. É o nome do arquivo do TimebankPT\n",
      " |  \n",
      " |  get_nome_doc_unico(self)\n",
      " |      Retorna primeiro nome de documento da lista de nomes de documentos (self.nome_doc).\n",
      " |      \n",
      " |      Return:\n",
      " |          string\n",
      " |  \n",
      " |  get_sentenca_texto(self, id_sentenca=None)\n",
      " |      Retorna lista contendo texto da sentença com as tag TimeML, conforme id_sentenca setadas em set_id_sentenca() ou informado no parâmetro id_sentenca\n",
      " |  \n",
      " |  get_sentenca_texto_doc(self)\n",
      " |      Retorna lista de texto de todas as sentenças do documento da primeira sentença de get_id_sentenca().\n",
      " |  \n",
      " |  get_sentenca_texto_tag(self, id_sentenca=None)\n",
      " |      Retorna lista contendo texto da sentença com as tag TimeML, conforme id_sentenca setadas em set_id_sentenca().\n",
      " |  \n",
      " |  get_train_test(self, id_sentenca)\n",
      " |      Retorna qual o grupo de desenvolvimento que a sentença pertença.\n",
      " |      \n",
      " |      Args:\n",
      " |          id_sentenca: id da sentença\n",
      " |      \n",
      " |      Return:\n",
      " |          train:      Se é uma sentença de treino.\n",
      " |          train_test: Se é uma sentença de teste para o conjunto de treino (Dev).\n",
      " |          test:       Se é uma sentença de teste global. Utilizado apenas no trabalho final.\n",
      " |  \n",
      " |  id_sentencas_task(self, task)\n",
      " |      Retorna id_sentenca contenpladas com cada tipo de task\n",
      " |  \n",
      " |  pesquisa_id_sentenca(self, lista_termos, formato_dataframe=False)\n",
      " |      Retorna DataFrame com resultado pesquisa dos termos\n",
      " |      \n",
      " |      Args:\n",
      " |          lista_termos: lista de palavras a ser pesquisada em sentenças\n",
      " |          \n",
      " |          formato_dataframe: se True, retorna o dataframe filtrado por lista_termos, se não, retorna lista de id_sentenca que atendem ao critério de pesquisa\n",
      " |  \n",
      " |  pesquisa_sentenca_texto(self, lista_termos='', formato_dataframe=False)\n",
      " |      Retorna DataFrame com resultado pesquisa dos termos\n",
      " |      \n",
      " |      Args:\n",
      " |          lista_termos: lista de palavras a ser pesquisada em sentenças\n",
      " |          \n",
      " |          formato_dataframe: se True, retorna o dataframe filtrado por lista_termos, se não, retorna lista de sentencas que atendem ao critério de pesquisa\n",
      " |  \n",
      " |  print_pipes(self)\n",
      " |      Imprime a sequência dos pipelines executados\n",
      " |  \n",
      " |  query_filtro_task(self, task: str)\n",
      " |      Retorna query que filtra sentencas conforme task\n",
      " |  \n",
      " |  remove_pipe_timebank(self)\n",
      " |      Remove o pipe_timabankpt. Retira as tag dos timabankpt (EVENT e TIMEX3)\n",
      " |  \n",
      " |  set_id_sentenca(self, *id_sentenca)\n",
      " |      Atribui as id_sentenca para as instâncias da classe e atribui valores a campos que dependem de id_sentenca\n",
      " |      \n",
      " |      Args:\n",
      " |          id_sentenca: Lista de id_sentença. O id_senteca não conta nos arquivos TimeML, foram criados na função timeml_to_df para facilitar o acesso.\n",
      " |          id_sentenca pode ser vários inteiros, várias strings, lista de ambos ou strings separadas por virgulas.\n",
      " |  \n",
      " |  set_sentenca_texto(self, sentenca_texto)\n",
      " |      Permite atribuir sentenças que não estão no TimebankPT para submetê-las ao pipeline do spaCy.\n",
      " |      Caso a sentenca passada exista no TimabankPT, atribui a id_sentenca à classe com set_id_sentenca()\n",
      " |      \n",
      " |      Args:\n",
      " |          sentenca_texto: Lista de sentenças ou sentença única.\n",
      " |  \n",
      " |  trata_lista(self, *dados, tipo_lista=<class 'int'>)\n",
      " |      Retorna dados convertido em lista de strings.\n",
      " |      \n",
      " |      Args:\n",
      " |          dados: Pode vários inteiros, várias strings, lista de ambos ou strings separadas por virgulas.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  dct_doc\n",
      " |      Retorna lista com Data de Criação do Documento(DCT) da id_sentença setada em set_id_sentenca() ou str da id_sentenca do parametro\n",
      " |      \n",
      " |      Args:\n",
      " |          nome_doc: se informado, sobrepõe as id_sentenca atribuida em set_id_sentenca()\n",
      " |      \n",
      " |      Return:\n",
      " |          lista com DCT.\n",
      " |  \n",
      " |  doc\n",
      " |      Retorna lista de objetos Doc do spaCy\n",
      " |      \n",
      " |      Return:\n",
      " |          Lista de Docs\n",
      " |  \n",
      " |  doc_root\n",
      " |      Retorn o root do Doc.\n",
      " |      Se root for pontuação, verificar se não há outro root que não seja pontuação.\n",
      " |  \n",
      " |  doc_unico\n",
      " |      Retorna o primeiro Doc da lista de Docs (self.doc).\n",
      " |      \n",
      " |      Return:\n",
      " |          Doc\n",
      " |  \n",
      " |  id_sentenca_unica\n",
      " |      Retorna lista com a primeira id_sentenca da lista de senteças setadas em set_id_sentenca()\n",
      " |  \n",
      " |  id_sentencas_dep\n",
      " |      Retorna também lista de id_sentenca dependentes da sentenca do documento atual.\n",
      " |  \n",
      " |  id_sentencas_doc\n",
      " |      Retorna lista de todas id_sentenca do primeiro documento da lista de documentos atual.\n",
      " |      O nome do documento é o nome do arquivo do TimeBankPT.\n",
      " |  \n",
      " |  nome_doc\n",
      " |      Retorna lista com nome do documento da id_sentença setada em set_id_sentenca() ou str da id_setenca do parametro\n",
      " |      \n",
      " |      Args:\n",
      " |          id_sentenca: se informado, sobrepõe id_sentenca atribuido em set_id_sentenca()\n",
      " |      \n",
      " |      Return:\n",
      " |          Nome de documentos. É o nome do arquivo do TimebankPT\n",
      " |  \n",
      " |  nome_doc_unico\n",
      " |      Retorna primeiro nome de documento da lista de nomes de documentos (self.nome_doc).\n",
      " |      \n",
      " |      Return:\n",
      " |          string\n",
      " |  \n",
      " |  sentenca_texto_doc\n",
      " |      Retorna lista de texto de todas as sentenças do documento da primeira sentença de get_id_sentenca().\n",
      " |  \n",
      " |  sentenca_texto_tag\n",
      " |      Retorna lista contendo texto da sentença com as tag TimeML, conforme id_sentenca setadas em set_id_sentenca().\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  id_sentenca\n",
      " |      Retorna as id_sentenca setadas em set_id_sentenca() se texto_sentenca não for informado\n",
      " |      \n",
      " |      Se texto_sentenca for informado:      \n",
      " |          Busca a id_sentenca correspondente à texto_sentenca no TimeBankPt, e a retorna.\n",
      " |      \n",
      " |      Args: \n",
      " |          texto_sentenca: Texto da sentença a ser procurada em TimeBankPt\n",
      " |          \n",
      " |      Return:\n",
      " |          list id_sentenca\n",
      " |  \n",
      " |  sentenca_texto\n",
      " |      Retorna lista contendo texto da sentença com as tag TimeML, conforme id_sentenca setadas em set_id_sentenca() ou informado no parâmetro id_sentenca\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  Df = <class 'parse.ParseTimebankPT.TimebankPT.Df'>\n",
      " |      Cria DataFrame para os diversos elementos do corpus TimebankPT: EVENT, TIMEX3, TLINK, Sentenças, Nome do Documento e Data de Criação do Documento (DCT)\n",
      " |  \n",
      " |  \n",
      " |  MyTlink = <class 'parse.ParseTimebankPT.TimebankPT.MyTlink'>\n",
      " |      Recebe as Relações Temporais descobertas pelo método aqui proposto.\n",
      " |      Salva-as em arquivo no mesmo formato das tag TLINK do corpus TimebankPT.\n",
      " |      Fornece impressão gráfica das relações.\n",
      " |  \n",
      " |  \n",
      " |  Print = <class 'parse.ParseTimebankPT.TimebankPT.Print'>\n",
      " |      Formata para impressão em tela os elementos do Timebank e recursos do spaCy como Entidades, POS, Morph, árvore de dependência.\n",
      " |  \n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Functions:\n",
      " |  \n",
      " |  explicar_spacy(self, elemento)\n",
      " |      Retorna descrição explecativa sobre elementos POS e DEP do spaCy.\n",
      " |  \n",
      " |  get_class_list(self, obj=None)\n",
      " |      Retorna lista com as propriedades, funções e tipos presentes no objeto atual.\n",
      " |  \n",
      " |  train_test(self, nome_arquivo: str) -> bool\n",
      " |      Retorna se o arquivo é de teste ou de treino, baseado no subdiretório onde cada tipo está armazenado.\n",
      " |      \n",
      " |      Args:\n",
      " |          nome_arquivo: nome do arquivo que represente um documento do corpus.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Functions:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1015ae8-5798-49e2-b952-ae1f7c955951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m  \u001b[0mtb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'TimebankPT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      Cria DataFrame para os diversos elementos do corpus TimebankPT: EVENT, TIMEX3, TLINK, Sentenças, Nome do Documento e Data de Criação do Documento (DCT)\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Inicializa classe recebendo instancia de TimebankPT (tb) e carrega dados dos arquivos do corpus para Dataframes.\n",
       "\n",
       "Args:\n",
       "    tb: Recebe instancia da classe TimebankPT\n",
       "    \n",
       "\u001b[1;31mFile:\u001b[0m           e:\\backup_online\\onedrive\\documents\\dárcio online\\pós-graduação\\mestrado\\experimentos\\parse\\parsetimebankpt.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? tb.Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d89541-9849-4731-a06a-a7bcfcef1dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Df in module parse.ParseTimebankPT object:\n",
      "\n",
      "class Df(builtins.object)\n",
      " |  Df(tb: 'TimebankPT')\n",
      " |  \n",
      " |  Cria DataFrame para os diversos elementos do corpus TimebankPT: EVENT, TIMEX3, TLINK, Sentenças, Nome do Documento e Data de Criação do Documento (DCT)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tb: 'TimebankPT')\n",
      " |      Inicializa classe recebendo instancia de TimebankPT (tb) e carrega dados dos arquivos do corpus para Dataframes.\n",
      " |      \n",
      " |      Args:\n",
      " |          tb: Recebe instancia da classe TimebankPT\n",
      " |  \n",
      " |  atualizar_filtros(self)\n",
      " |      Carrega os DataFrames filtrados conforme parametros.\n",
      " |      É chamada senpre que uma propriedade da classe é alterado, por exemplo, set_id_sentenca, set_sentenca_texto, recursivo.\n",
      " |  \n",
      " |  lista_arquivos(self)\n",
      " |      Retorna lista de arquivos do path.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  dados_pipe\n",
      " |      Retorna dicionario contendo os dados necessários para o processamento do pipeline do spaCy: pipe_timebankpt.\n",
      " |      \n",
      " |      Return:\n",
      " |          {\n",
      " |              'texto da sentença': \n",
      " |              {\n",
      " |                  'isentenca': 'id sentença',\n",
      " |                  'doc': 'nome do arquivo doc',\n",
      " |                  'dct': 'data de criação do documento',\n",
      " |                  'lista_event': [[], [], []],\n",
      " |                  'lista_timex3': [[], []]\n",
      " |              },\n",
      " |              \n",
      " |              'Repetidamente, ele resiste.':\n",
      " |              {  \n",
      " |                  'isentenca': '254', \n",
      " |                  'doc': 'ABC19980120.1830.0957', \n",
      " |                  'dct': '1998-01-20', \n",
      " |                  'lista_event': [['EVENT', '2', 'e1', 'previram', 14, 22, 'I_ACTION', 'NONE'], ['EVENT', '2', 'e86', 'queda', 29, 34, 'OCCURRENCE', 'NONE']], \n",
      " |                  'lista_timex3': [['TIMEX3', '10', 't94', 'quase quarenta anos', 8.0, 27.0, 'DURATION', 'P40Y']]\n",
      " |              }\n",
      " |          }\n",
      " |  \n",
      " |  documento\n",
      " |      Retorna DataFrame contendo atributos do documento da sentença informada para a class.\n",
      " |  \n",
      " |  documento_completo\n",
      " |      Retorna DataFrame contendo atributos de todos os documento do corpus.\n",
      " |  \n",
      " |  event\n",
      " |      Retorna DataFrame contendo todos atributos de EVENT, porém apenas das sentenças informada para a class.\n",
      " |  \n",
      " |  event_completo\n",
      " |      Retorna DataFrame contendo todos atributos de EVENT de todas as sentenças do corpus.\n",
      " |  \n",
      " |  event_doc\n",
      " |      Retorna DataFrame contendo todos atributos de EVENT, porém apenas as sentenças do documento atual.\n",
      " |  \n",
      " |  quant_doc\n",
      " |  \n",
      " |  quant_doc_total\n",
      " |  \n",
      " |  quant_event\n",
      " |  \n",
      " |  quant_event_total\n",
      " |  \n",
      " |  quant_sentenca\n",
      " |  \n",
      " |  quant_sentenca_total\n",
      " |  \n",
      " |  quant_timex3\n",
      " |  \n",
      " |  quant_timex3_total\n",
      " |  \n",
      " |  quant_tlink\n",
      " |  \n",
      " |  quant_tlink_total\n",
      " |  \n",
      " |  sentenca\n",
      " |      Retorna DataFrame contendo atributos das sentenças informadas para a class.\n",
      " |  \n",
      " |  sentenca_completo\n",
      " |      Retorna DataFrame contendo atributos de todas as sentenças do corpus.\n",
      " |  \n",
      " |  sentenca_doc\n",
      " |      Retorna DataFrame contendo todos atributos da sentença, porém apenas as sentenças do documento atual.\n",
      " |  \n",
      " |  timex3\n",
      " |      Retorna DataFrame contendo todos atributos de TIMEX3, porém apenas das sentenças informada para a class.\n",
      " |  \n",
      " |  timex3_completo\n",
      " |      Retorna DataFrame contendo todos atributos de TIMEX3 de todas as sentenças do corpus.\n",
      " |  \n",
      " |  timex3_doc\n",
      " |      Retorna DataFrame contendo todos atributos de TIMEX3, porém apenas as sentenças do documento atual.\n",
      " |  \n",
      " |  tlink\n",
      " |      Retorna DataFrame contendo todos atributos de TLINK, porém apenas das sentenças informadas para a class.\n",
      " |  \n",
      " |  tlink_completo\n",
      " |      Retorna DataFrame contendo todos atributos de TLINK de todas as sentenças do corpus.\n",
      " |  \n",
      " |  tlink_doc\n",
      " |      Retorna DataFrame contendo todos atributos de TLINK, porém apenas os registros do documento atual.\n",
      " |  \n",
      " |  tlink_join\n",
      " |      Retorna DataFrame de TLink unido com os campos das chaves estrangeira.\n",
      " |      Dar uma visão mais global dos campos de TLink.\n",
      " |  \n",
      " |  tlink_join_completo\n",
      " |      Retorna DataFrame de TLink completo unido com os principais campos das chaves estrangeira.\n",
      " |      Exibe todos os registros de TLink.\n",
      " |  \n",
      " |  tlink_join_doc\n",
      " |      Retorna DataFrame contendo todos atributos de TLINK e suas chaves extrangeiras, porém apenas os registros do documento atual.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  recursivo\n",
      " |      Propriedade booleana da class que indica se as sentenças dependentes serão também exibidas.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tb.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9062e653-d88b-4947-b76c-715f158ef4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m  \u001b[0mtb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'TimebankPT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      Formata para impressão em tela os elementos do Timebank e recursos do spaCy como Entidades, POS, Morph, árvore de dependência.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Inicializa classe recebendo instancia da classe TimebankPT (tb)\n",
       "\n",
       "Args:\n",
       "    tb: Instancia da classe TimebankPT.\n",
       "    \n",
       "\u001b[1;31mFile:\u001b[0m           e:\\backup_online\\onedrive\\documents\\dárcio online\\pós-graduação\\mestrado\\experimentos\\parse\\parsetimebankpt.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? tb.Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c000dd-a4d7-4586-ace2-a0c982d7629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Print in module parse.ParseTimebankPT object:\n",
      "\n",
      "class Print(builtins.object)\n",
      " |  Print(tb: 'TimebankPT')\n",
      " |  \n",
      " |  Formata para impressão em tela os elementos do Timebank e recursos do spaCy como Entidades, POS, Morph, árvore de dependência.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tb: 'TimebankPT')\n",
      " |      Inicializa classe recebendo instancia da classe TimebankPT (tb)\n",
      " |      \n",
      " |      Args:\n",
      " |          tb: Instancia da classe TimebankPT.\n",
      " |  \n",
      " |  ent(self, id_sentenca=None)\n",
      " |      Imprime Entidades Nomeadas, inclusive as tags EVENT e TIMEX3 do TimebankPT se o seu pipeline estiver adicionado ao spaCy.\n",
      " |  \n",
      " |  filhos(self, id_sentenca=None)\n",
      " |      Imprime também os dependentes (filhos) de cada token.\n",
      " |  \n",
      " |  graph(self, id_sentenca=None, size='m', compact=True, punct=False)\n",
      " |      Imprime gráfico de análise de dependência.\n",
      " |      \n",
      " |      Args:\n",
      " |          id_sentenca: se fornecida lista de id_sentenca\n",
      " |          size: 'p', 'm', 'g' representa a distancia entre os tokens\n",
      " |          punct: se True, mostra as pontuações no grafo.\n",
      " |  \n",
      " |  graph_dfs(self, id_sentenca=None, mostrar_mais=True)\n",
      " |      Imprime arvore sintática utilizanto a Busca por Profundidade\n",
      " |  \n",
      " |  graph_treelib(self, id_sentenca=None)\n",
      " |      Imprime arvore sintática utilizanto a Busca por Profundidade com a biblioteca treelib\n",
      " |      from treelib import Node, Tree\n",
      " |  \n",
      " |  imprimir_campos(self, func_campos, id_sentenca=None)\n",
      " |      Função genérica que recebe dados de tokens (em func_campos) para imprimi-los. \n",
      " |      Os dados contem classes gramaticais (Part Of Speech), análise morfológica, análise de dependência e tags do corpus TimebankPT.\n",
      " |      \n",
      " |      Args:\n",
      " |          func_campos: Função que retorna dicionário contendo dados dos tokens que serão impressos. Os dados estão em funções iniciadas por '__campos_', ex: __campos_timebank, __campos_morph ...\n",
      " |  \n",
      " |  morph(self, id_sentenca=None)\n",
      " |      Imprime Classes gramaticais (Part Of Speech) e análise morfológica.\n",
      " |  \n",
      " |  pais(self, id_sentenca=None)\n",
      " |      Imprime também os ancestrais de cada token.\n",
      " |  \n",
      " |  timebank(self, id_sentenca=None)\n",
      " |      Imprime tags do timebank.\n",
      " |  \n",
      " |  tokens(self, id_sentenca=None)\n",
      " |      Imprime tags POS.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tb.print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab61bcd-a88e-4eba-b009-7122137890d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m  \u001b[0mtb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMyTlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'TimebankPT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Recebe as Relações Temporais descobertas pelo método aqui proposto.\n",
       "Salva-as em arquivo no mesmo formato das tag TLINK do corpus TimebankPT.\n",
       "Fornece impressão gráfica das relações.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Recebe instancia da classe TimebankPT e e inicializa estrutura de dados para o gráfico das Relações Temporais.\n",
       "\n",
       "Args:\n",
       "    tb: Instancia da classe TimebankPT.\n",
       "\u001b[1;31mFile:\u001b[0m           e:\\backup_online\\onedrive\\documents\\dárcio online\\pós-graduação\\mestrado\\experimentos\\parse\\parsetimebankpt.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? tb.MyTlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a63e14a-a5f3-4dc4-8206-8811f1b97887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MyTlink in module parse.ParseTimebankPT object:\n",
      "\n",
      "class MyTlink(builtins.object)\n",
      " |  MyTlink(tb: 'TimebankPT')\n",
      " |  \n",
      " |  Recebe as Relações Temporais descobertas pelo método aqui proposto.\n",
      " |  Salva-as em arquivo no mesmo formato das tag TLINK do corpus TimebankPT.\n",
      " |  Fornece impressão gráfica das relações.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tb: 'TimebankPT')\n",
      " |      Recebe instancia da classe TimebankPT e e inicializa estrutura de dados para o gráfico das Relações Temporais.\n",
      " |      \n",
      " |      Args:\n",
      " |          tb: Instancia da classe TimebankPT.\n",
      " |  \n",
      " |  add(self, relType, eventID, relatedTo, task, isentenca, doc, rule, lid=None)\n",
      " |      Adiciona tags Tlink descoberta pelo método proposto à estrutura de dados armazenada em to_list.\n",
      " |      \n",
      " |      Args:\n",
      " |          relType: Tipo da relação temporal predita\n",
      " |          eventID: ID do EVENT \n",
      " |          relatedTo: Pode ser relatedToTime ou relatedToEvent, é inferida através de task\n",
      " |          task: Tipo da tarefa do Tempeval. \n",
      " |              A. EVENT-TIMEX3 (maioria intra-sentença)\n",
      " |              B. EVENT-DCT  \n",
      " |              C. EVENT-EVENT (inter-sentença)\n",
      " |          isentenca: id_sentenca\n",
      " |          doc: nome do arquivo do corpus, representa um documento\n",
      " |          rule: código da regra que previu o tipo de relação\n",
      " |          lid: ID do TLINK. Se não for fornecido, é calculado automaticamente, último + 1.\n",
      " |  \n",
      " |  clear(self)\n",
      " |      Limpa todas as tags TLink adicionadas.\n",
      " |  \n",
      " |  graph_rt(self, compact=True, punct=False)\n",
      " |      Exibe as relações temporais em forma gráfica.\n",
      " |  \n",
      " |  idtag_to_token(self, id_tag: str) -> spacy.tokens.token.Token\n",
      " |  \n",
      " |  idtag_to_token_next(self, id_tag: str) -> spacy.tokens.token.Token\n",
      " |  \n",
      " |  lista_id_timebank(self, task)\n",
      " |      Retorna dicionário contendo pares conforme task.\n",
      " |      \n",
      " |      Args:\n",
      " |          task: A. EVENT-TIMEX3 (intra-sentença)\n",
      " |                B. EVENT-DCT \n",
      " |                C. EVENT-EVENT (inter-sentença consecutivas)\n",
      " |  \n",
      " |  load_from_file(self, file_tlink, modo='w')\n",
      " |      ######### PROVAVELMENTE ESTE MÉTODO SERÁ EXCLUIDO -> ANALISAR ISSO DEPOIS\n",
      " |      \n",
      " |      Carrega dados do arquivo salvo dados pelo método save_to_file()\n",
      " |      \n",
      " |      Args:\n",
      " |          file_tlink: Arquivo tml contendo tags TLINK criado pelo método save_to_file()\n",
      " |      \n",
      " |          modo: se 'w' (write), limpa as carga anterior de self.to_list, sobrescreve conteudo já carragado.\n",
      " |                se 'a' (append), adiciona a carga atual no final da carga existente.\n",
      " |  \n",
      " |  remove(self, relType, eventID, relatedTo, task, isentenca, doc, rule, lid=None)\n",
      " |      Remove TLink da estrutuda de dados.\n",
      " |      Busca par eventID e relatedTo e apaga pelo lid encontrado.\n",
      " |  \n",
      " |  save_to_file(self, file_tlink, sobrescrever=False)\n",
      " |      Salva as tags TLINK em arquivo.\n",
      " |      \n",
      " |      Args:\n",
      " |          file_tlink: Nome do arquivo tml que conterá tags TLINK.\n",
      " |      \n",
      " |          sobrescrever: Se True, sobrescreve o arquivo file_tlink se ele existir, se não existir, cria-o.\n",
      " |                        Se False, se o arquivo existir, não sobrescreve, não faz nada. Se o arquivo não existir, cria-o.\n",
      " |  \n",
      " |  tabela_id_timebank(self)\n",
      " |      Retorna tabela contendo todas entidades EVENT e TIMEX3 da sentença e seus respectivos IDs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  to_df\n",
      " |      Lista tags TLink extraídas em formato DataFrame\n",
      " |  \n",
      " |  to_df_join\n",
      " |      Retorna DataFrame de MyTlink contendo os dados principais das chaves extrangeiras.\n",
      " |  \n",
      " |  to_list\n",
      " |      Estrutura de dados utilizada para armazenar as tags TLink.\n",
      " |      Utilizada para criar DataFrames e alimentar impressão gráfica das relações temporais.\n",
      " |  \n",
      " |  to_txt\n",
      " |      Lista tags TLink em formato padrão das tags TLINK dos arquivos do corpus.\n",
      " |      Utilizada para salvar em arquivo.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tb.my_tlink)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8ddf9-80e3-4ea3-8962-99006e8c01a9",
   "metadata": {},
   "source": [
    "### Relações Temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4fc9257-36f8-4825-9965-4827741fedeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m  \u001b[0mRelacaoTemporal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'TimebankPT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      Atribui relações temporais às sentencas.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Iniciaza classe RelacaoTemporal.\n",
       "\n",
       "Args:\n",
       "    tb: instancia da class TimebankPT\n",
       "    \n",
       "\u001b[1;31mFile:\u001b[0m           e:\\backup_online\\onedrive\\documents\\dárcio online\\pós-graduação\\mestrado\\experimentos\\parse\\parsetimebankpt.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? RelacaoTemporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b341da0f-6035-4f0f-81d8-81fb3fc2125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on RelacaoTemporal in module parse.ParseTimebankPT object:\n",
      "\n",
      "class RelacaoTemporal(builtins.object)\n",
      " |  RelacaoTemporal(tb: 'TimebankPT')\n",
      " |  \n",
      " |  Atribui relações temporais às sentencas.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tb: 'TimebankPT')\n",
      " |      Iniciaza classe RelacaoTemporal.\n",
      " |      \n",
      " |      Args:\n",
      " |          tb: instancia da class TimebankPT\n",
      " |  \n",
      " |  cm(self, extras=True)\n",
      " |      Matrix de Confusão das predições.\n",
      " |      \n",
      " |      Args:\n",
      " |          extras: se True (default), exibe as predições que não estão anotadas no corpus\n",
      " |                  se False, não considera as predições que não estão anotadas.\n",
      " |  \n",
      " |  convert_id_to_token(self, eventID: str, relatedTo: str) -> tuple\n",
      " |      Converte ids de EVENT e TIMEX3 para Token.\n",
      " |      \n",
      " |      Args:\n",
      " |          eventID: ID do EVENT no corpus\n",
      " |          relatedTo: ID do TIMEX3 ou EVENT no corpus\n",
      " |      \n",
      " |      Return\n",
      " |          Tupla contendo tokens que representam a entidade EVENT e/ou TIMEX3.\n",
      " |  \n",
      " |  ct(self, extras=True)\n",
      " |      Cross Tab.\n",
      " |      \n",
      " |      Args:\n",
      " |          extras: se True (default), exibe as predições que não estão anotadas no corpus\n",
      " |                  se False, não considera as predições que não estão anotadas.\n",
      " |  \n",
      " |  df_real_predict_id_sentenca(self, id_sentenca=None, extra: bool = False)\n",
      " |      Une dados real do corpus com os dados previsto.\n",
      " |      \n",
      " |      Args:\n",
      " |          id_sentenca: Se informada, filtra por id_sentenca.\n",
      " |          extra: Se True, exibe as previsões que não estão anotadas no corpus, se False (default), exibe apenas as previsões que há correspondência no corpus.\n",
      " |  \n",
      " |  get_sort_reverse(self)\n",
      " |      Obtem a informação sobre se a ordem das regras está ascendente ou descendente.\n",
      " |  \n",
      " |  get_sort_rules(self) -> str\n",
      " |      Obtem a ordem atual das regras.\n",
      " |  \n",
      " |  graph_pred(self, id_sentenca=None)\n",
      " |      Exibe as relações temporais de forma gráfica da primeira sentença setada.\n",
      " |  \n",
      " |  process_resume(self)\n",
      " |      <<Precisa desbabunçar isso aqui>>\n",
      " |      \n",
      " |      Exibe resultado do processamentos do processamento das regras\n",
      " |  \n",
      " |  process_rules(self, id_sentencas=None)\n",
      " |      Realiza predição de relações temporais em todos os pares entre EVENT e TIMEX3 de todas as sentenças, conforme a tarefa.\n",
      " |      Preenche estrutura 'self.__tb.my_tlink' com dados da predição.\n",
      " |      \n",
      " |      Args:\n",
      " |          id_sentencas: Se não for informado, processa todas as sentenças cobertas pela task atual.\n",
      " |  \n",
      " |  sort_rules(self, order: str, reverse=False)\n",
      " |      Ordena as regras.\n",
      " |      A ordem atual pode ser obtida pelo método 'get_sort_rules()'\n",
      " |      \n",
      " |      Args:\n",
      " |          Order: 'codigo_regra', 'tipo_relacao', 'ordem', 'random'\n",
      " |                 se as regras forem processadas, permite que seja uma lista de cod_regras\n",
      " |  \n",
      " |  sort_rules_accuracy(self, show_accuracy: bool = False)\n",
      " |      Retorna lista de cod_regra ordenada por acurácia.\n",
      " |      As regras são processadas individualmente, ou seja, todos os pares são processados por apenas uma regra de cada vez.\n",
      " |      O objetivo é evitar interferências de uma regra sobre outra.\n",
      " |      \n",
      " |      O resultado poderá ser utilizado para processar o conjunto de teste em ordem de acurácia, ex: rt.sort_rules(sort_rules_accuracy: list)\n",
      " |  \n",
      " |  status(self)\n",
      " |      Exibe as principais configurações da instancia da classe.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  df_features\n",
      " |      Dataframe contendo features dos tokens EVENT e TIMEX3 que poderão ser TLinks.\n",
      " |      Utilizado para análises manuais na seleção de TLinkCandidate \n",
      " |      e para alimentar dados para treinamento do modelo de machine learning\n",
      " |  \n",
      " |  df_pred\n",
      " |      Exibe em DataFrame as predição de relações temporais processadas pelo método process_rules().\n",
      " |  \n",
      " |  df_real\n",
      " |      Sentenças anotadas no corpus que atendem aos critérios de cada task.\n",
      " |  \n",
      " |  df_real_predict\n",
      " |      Retorna dataframe com dados real do corpus e com dados previstos unidos.\n",
      " |      Apenas aquelas previsões em que há correspondência no corpus.\n",
      " |  \n",
      " |  df_real_predict_extra\n",
      " |      Retorna dataframe com dados real do corpus e com dados previstos unidos.\n",
      " |      Inclui também as previsões que não estão anotadas no corpus.\n",
      " |  \n",
      " |  df_resultado_geral\n",
      " |      Retorna resumo do resultado geral.\n",
      " |  \n",
      " |  df_resultado_por_classe\n",
      " |  \n",
      " |  df_resultado_por_documento\n",
      " |  \n",
      " |  df_resultado_por_regras\n",
      " |  \n",
      " |  df_resultado_por_sentenca\n",
      " |  \n",
      " |  df_resultado_por_task\n",
      " |  \n",
      " |  df_rules\n",
      " |      Exibe as regras ativas em formato de tabela.\n",
      " |  \n",
      " |  id_sentencas_sem_predicao\n",
      " |      Lista de ed_sentenca que ainda não houve predição.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  active_tlink_candidate\n",
      " |      Propriedade booleana que informa à classe se serão ou não selecionados EVENTs com maior probabilidade se estaram anotados no corpus para posterior geração de TLINKs.\n",
      " |  \n",
      " |  active_tlink_transitive\n",
      " |      Propriedade booleana que informa à classe se serão adicionados TLINKs transitivos aos TLINKs preditos pelo sistema.\n",
      " |  \n",
      " |  processing_type\n",
      " |      Propriedade que define a forma como as regras serão processadas.\n",
      " |      Se igual a 'votacao' -> Todas as regras são processadas para todos os pares de relação. A relação temporal mais frequente é retornada. (default)\n",
      " |                 'peneira' -> A relação temporal do par é retornada na primeira regra que casar. Para o par atual, as outras regras não são processadas.\n",
      " |  \n",
      " |  rules\n",
      " |      Lista de regras que serão passadas à instancia da classe para processamento através do método process_rules().\n",
      " |      \n",
      " |      Args:\n",
      " |          rules: lista de listas, no formato: \n",
      " |                 [[código regra: float, tipo de relação temporal: str, ordem de execução: float, expressão lógica que representa a regra: str], ]\n",
      " |                 As funções auxiliares das regras são acessadas com o prefixo 'self.f'. \n",
      " |                 Ex: [249, \"OVERLAP\", 2, \"self.f.is_dependencyType(tokenT, tokenE, 'conj')\"]\n",
      " |                 \n",
      " |                 #A 'ordem de execução' com números negativos torna a regra inativa.\n",
      " |  \n",
      " |  rules_filter\n",
      " |      Filtra as regras a serem processadas pelo códigos das regras informadas.\n",
      " |      Esta função altera as self.rules. para desfazer o filtro, é necessário é necessário atribuir as regras novamente: self.rules = listas_das_regras.\n",
      " |      \n",
      " |      Args: \n",
      " |          lista_cod_regras: lista de códigos das regras.\n",
      " |  \n",
      " |  task\n",
      " |      Define o tipo de tarefa que será processada.\n",
      " |      Pode ser: 'A', 'B', 'C'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  TokenDct = <class 'parse.ParseTimebankPT.RelacaoTemporal.TokenDct'>\n",
      " |      #para task B\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a2cab-d722-4668-9559-6d56c70f6a51",
   "metadata": {},
   "source": [
    "#### Funções auxiliares na composição das regras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a476cf-db2b-4617-acb1-262b54e97463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m  \u001b[0mRulesFunctions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'TimeBankPT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      Funções auxiliares das regras para extrair Relações Temporais.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Inicializa a classe.\n",
       "\n",
       "Args:\n",
       "    doc: objeto Doc atual da class TimebankPT.\n",
       "    \n",
       "\u001b[1;31mFile:\u001b[0m           e:\\backup_online\\onedrive\\documents\\dárcio online\\pós-graduação\\mestrado\\experimentos\\temporal_relation\\parse\\parsetimebankpt.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from parse.ParseTimebankPT import RulesFunctions\n",
    "? RulesFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660f6837-f0e9-41b5-8505-1381d58e6ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RulesFunctions in module parse.ParseTimebankPT:\n",
      "\n",
      "class RulesFunctions(builtins.object)\n",
      " |  RulesFunctions(tb: 'TimeBankPT')\n",
      " |  \n",
      " |  Funções auxiliares das regras para extrair Relações Temporais.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tb: 'TimeBankPT')\n",
      " |      Inicializa a classe.\n",
      " |      \n",
      " |      Args:\n",
      " |          doc: objeto Doc atual da class TimebankPT.\n",
      " |  \n",
      " |  classe(self, token: spacy.tokens.token.Token, classe: list) -> bool\n",
      " |      Verifica se 'token' é uma das classes de evetos da lista 'classe'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Token\n",
      " |          classe: lista de classes do evento\n",
      " |  \n",
      " |  closelyFollowing(self, token1: spacy.tokens.token.Token, token2: spacy.tokens.token.Token, distancia=10) -> bool\n",
      " |      Retorna True se os token estiverem a uma distancia de no máximo 'distancia' tokens.\n",
      " |  \n",
      " |  contextBy(self, token: spacy.tokens.token.Token, tipo: \"'str', 'str_lemma', 'token', 'digito', 'pos', 'dep', 'morph'\", valor=None, distancia='max', contexto: 'antes, depois' = None) -> bool\n",
      " |      Procura elementos na sentença conforme o tipo e a partir do 'token' na direção do contexto.\n",
      " |  \n",
      " |  dep(self, token: spacy.tokens.token.Token, dep: list) -> bool\n",
      " |      Verifica se 'token' possue um dos tipos de dependência da lista 'dep'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Token\n",
      " |          dep: lista de tipo de dependências.\n",
      " |  \n",
      " |  dependencyType(self, tokenPai: spacy.tokens.token.Token, tokenFilho: spacy.tokens.token.Token) -> str\n",
      " |      Retorna a relação de dependência entre 'tokenPai' e 'tokenFilho'.\n",
      " |      \n",
      " |      Args:\n",
      " |          tokenPai: governor\n",
      " |          tokenFilho: dependent\n",
      " |      \n",
      " |      Retorna\n",
      " |          String que representa o tipo de dependência de tokenFilho para tokenPai.\n",
      " |  \n",
      " |  followedBy(self, token: spacy.tokens.token.Token, tipo: \"string: 'str', 'str_lemma', 'token', 'digito', 'pos', 'dep', 'morph'\", valor=None, distancia='max') -> bool\n",
      " |      Procura elementos na sentença depois do 'token', conforme o 'tipo'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: objeto Token do spaCy.\n",
      " |          tipo: string e pode ser:\n",
      " |                str       -> verifica se existe palavras especificada em valor \n",
      " |                          -> valor: str ou list; PODE SER OMITIDO.\n",
      " |                str_lemma -> verifica se existe palavras lematizadas especificada em valor \n",
      " |                          -> valor: str ou list;\n",
      " |                token     -> verifica se 'token' vem depois do outro token especificado em valor \n",
      " |                          -> valor: Token; PODE SER OMITIDO.\n",
      " |                digito    -> verifica se há digitos ou pos = 'NUM' -> Não tem valor;\n",
      " |                          -> Se valor for informado, ele será a distância.\n",
      " |                pos       -> verifica se há a classe gramatical especificada em valor \n",
      " |                          -> valor: list, ex: ['VERB', 'NOUM'];\n",
      " |                dep       -> verifica se há na árvore de dependencia o elemento especificado em valor \n",
      " |                          -> valor: list, ex: ['nsubj', 'nmod'];\n",
      " |                morph     -> verifica se há na análise morfológica o elemento especificado em valor \n",
      " |                          -> valor: tuple (key, value), ex: ('Tense', 'Fut'). Só é permitido uma tupla.\n",
      " |          valor: valor do elemento que será procurado, conforme o tipo.\n",
      " |          distancia: Se inteiro, é quantidade de tokens depois de 'token' onde a pesquisa será realizada.\n",
      " |                     Se string, a pesquisa será realizada em todos os tokens que vem depois 'token'.\n",
      " |  \n",
      " |  governVerb(self, token) -> spacy.tokens.token.Token\n",
      " |      Retorna o verbo pai mais próximo na hierarquia da árvore sintática.\n",
      " |  \n",
      " |  hasDepInBetween(self, token1: spacy.tokens.token.Token, token2: spacy.tokens.token.Token, dep: list)\n",
      " |      Verifica se existe a dependência 'dep' entre os dois tokens.\n",
      " |  \n",
      " |  hasDepInContext(self, token, dep: list, distancia=5, contexto=None) -> bool\n",
      " |      Verifica se existe a dependência 'dep' a uma distância de até 5 tokens, observando o contexto (antes ou depois do token).\n",
      " |  \n",
      " |  hasDepInContextFollow(self, token: spacy.tokens.token.Token, dep: list, distancia=5) -> bool\n",
      " |      Verifica se existe a dependência 'dep' a uma distância de até 5 tokens depois do 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: objeto Token\n",
      " |          distancia: Quantidade de tokens depois de 'token'. \n",
      " |                     Se 'max' (ou qualquer string), extende até o fim da sentença, conforme contexto.\n",
      " |  \n",
      " |  hasDepInContextPrecede(self, token: spacy.tokens.token.Token, dep: list, distancia=5) -> bool\n",
      " |      Verifica se existe a dependência 'dep' a uma distância de até 5 tokens antes do 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: objeto Token\n",
      " |          distancia: Quantidade de tokens antes de 'token'. \n",
      " |                     Se 'max' (ou qualquer string), extende até o início da sentença, conforme contexto.\n",
      " |  \n",
      " |  hasMorphInBetween(self, token1: spacy.tokens.token.Token, token2: spacy.tokens.token.Token, keyvalue: tuple)\n",
      " |      Verifica se existe na análise morfológica o 'key' de valor 'value' entre os dois tokens.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: objeto Token do spaCy.\n",
      " |          key: chave que representa a morfologia que deseja o valor, ex: Tense, VerbForm\n",
      " |          value: valor da key, ex: Fut, Inf\n",
      " |  \n",
      " |  hasMorphInContext(self, token: spacy.tokens.token.Token, keyvalue: tuple, distancia=5, contexto=None)\n",
      " |      Verifica se existe na análise morfológica o 'key' de valor 'value' a uma distância de até 5 tokens, observando o contexto (antes ou depois do token).\n",
      " |  \n",
      " |  hasMorphInContextFollow(self, token: spacy.tokens.token.Token, keyvalue: tuple, distancia=5)\n",
      " |      Verifica se existe na análise morfológica o 'key' de valor 'value' a uma distância de até 5 tokens depois de 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: objeto Token do spaCy.\n",
      " |          keyvalue: Tuple que representa o par da morfologia que deseja (key, value). \n",
      " |                    Ex:  (Tense, Fut) ou (VerbForm, Inf).\n",
      " |          distancia: Quantidade de tokens depois de 'token'. \n",
      " |                     Se 'max' (ou qualquer string), extende até o fim da sentença, conforme contexto.\n",
      " |  \n",
      " |  hasMorphInContextPrecede(self, token: spacy.tokens.token.Token, keyvalue: tuple, distancia=5)\n",
      " |      Verifica se existe na análise morfológica o 'key' de valor 'value' a uma distância de até 5 tokens antes de 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: objeto Token do spaCy.\n",
      " |          keyvalue: Tuple que representa o par da morfologia que deseja (key, value). \n",
      " |                    Ex:  (Tense, Fut) ou (VerbForm, Inf).\n",
      " |          distancia: Quantidade de tokens antes de 'token'. \n",
      " |                     Se 'max' (ou qualquer string), extende até o início da sentença, conforme contexto.\n",
      " |  \n",
      " |  hasNoVerbInBetween(self, token1: spacy.tokens.token.Token, token2: spacy.tokens.token.Token) -> bool\n",
      " |      Verifica se não há verbos entre os tokens de início e de fim.\n",
      " |  \n",
      " |  hasNoVerbInContext(self, token: spacy.tokens.token.Token, distancia=5, contexto=None) -> bool\n",
      " |      Checks for verb within entity_context of 5 words\n",
      " |      Verifica se existe VERBO a uma distância de até 5 tokens, observando o contexto (antes ou depois do token).\n",
      " |  \n",
      " |  hasNoVerbInContextFollow(self, token: spacy.tokens.token.Token, distancia=5) -> bool\n",
      " |      Verifica se existe VERBO a uma distância de até 5 tokens depois do 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: objeto Token\n",
      " |          distancia: Quantidade de tokens depois de 'token'. \n",
      " |                     Se 'max' (ou qualquer string), extende até o fim da sentença, conforme contexto.\n",
      " |  \n",
      " |  hasNoVerbInContextPrecede(self, token: spacy.tokens.token.Token, distancia=5) -> bool\n",
      " |      Verifica se existe VERBO a uma distância de até 5 tokens antes do 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: objeto Token\n",
      " |          distancia: Quantidade de tokens antes de 'token'. \n",
      " |                     Se 'max' (ou qualquer string), extende até o início da sentença, conforme contexto.\n",
      " |  \n",
      " |  hasPastParticipleInContext(self, token: spacy.tokens.token.Token, distancia=5, contexto: 'antes ou depois' = None)\n",
      " |      Verifica se há particípio passado a uma distância de até 5 tokens, observando o contexto (antes ou depois do token).\n",
      " |  \n",
      " |  hasPastParticipleInContextFollow(self, token: spacy.tokens.token.Token, distancia=5)\n",
      " |      Verifica se há particípio passado a uma distância de até 5 tokens depois do 'token'.\n",
      " |  \n",
      " |  hasPastParticipleInContextPrecede(self, token: spacy.tokens.token.Token, distancia=5)\n",
      " |      Verifica se há particípio passado a uma distância de até 5 tokens antes do 'token'.\n",
      " |  \n",
      " |  hasPosInBetween(self, token1: spacy.tokens.token.Token, token2: spacy.tokens.token.Token, pos: list) -> bool\n",
      " |      Verifica se existe a classe gramatical 'pos' entre os dois tokens.\n",
      " |  \n",
      " |  hasPosInContext(self, token, pos: list, distancia=5, contexto=None) -> bool\n",
      " |      Verifica se existe a classe gramatical 'pos' a uma distância de até 5 tokens, observando o contexto (antes ou depois do token).\n",
      " |  \n",
      " |  hasPosInContextFollow(self, token: spacy.tokens.token.Token, pos: list, distancia=5) -> bool\n",
      " |      Verifica se existe a classe gramatical 'pos' a uma distância de até 5 tokens depois do 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Objeto Token do spaCy.\n",
      " |          pos: Classe gramatical - POS Tag.\n",
      " |          distancia: Quantidade de tokens depois de 'token'. \n",
      " |                     Se 'max' (ou qualquer string), extende até o fim da sentença, conforme contexto.\n",
      " |  \n",
      " |  hasPosInContextPrecede(self, token: spacy.tokens.token.Token, pos: list, distancia=5) -> bool\n",
      " |      Verifica se existe a classe gramatical 'pos' a uma distância de até 5 tokens antes do 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Objeto Token do spaCy.\n",
      " |          pos: Classe gramatical - POS Tag.\n",
      " |          distancia: Quantidade de tokens antes de 'token'. \n",
      " |                     Se 'max' (ou qualquer string), extende até o início da sentença, conforme contexto.\n",
      " |  \n",
      " |  hasTenseVerbInBetween(self, token1: spacy.tokens.token.Token, token2: spacy.tokens.token.Token, tense)\n",
      " |      Verifica se tem VERB com tempo 'tense' entre dos dois tokens.\n",
      " |  \n",
      " |  hasWordInBetween(self, token1: spacy.tokens.token.Token, token2: spacy.tokens.token.Token, palavras, lemma: bool = False) -> bool\n",
      " |      Verifica se há 'palavras' entre a entidade 1 e entidade 2.\n",
      " |      \n",
      " |      Args:\n",
      " |          token1 e token2: objeto Token do spaCy.\n",
      " |          palavras: expressão que deseja encontrar. Pode ser string, lista de strings, Token ou expressão regular.\n",
      " |                    Pesquisa por palavras inteiras.\n",
      " |                    Regex gerado: (\\W|^)(palavras_separadas_por_pipe)(\\W|$)\n",
      " |          lemma: Se True, lematiza palavras e contexto.\n",
      " |  \n",
      " |  hasWordInContext(self, token: spacy.tokens.token.Token, palavras: list, distancia=5, contexto=None, lemma: bool = False) -> bool\n",
      " |      Verifica se existe uma das 'palavras' a uma certa distância do token, observando o contexto (antes ou depois do token).\n",
      " |  \n",
      " |  hasWordInContextFollow(self, token: spacy.tokens.token.Token, palavras: list, distancia=5, lemma: bool = False) -> bool\n",
      " |      Verifica se existe 'palavra' a uma distância de até 5 tokens depois do 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Objeto Token do spaCy\n",
      " |          palavras: Expressão que deseja encontrar. Pode ser string, lista de strings, Token ou expressão regular.\n",
      " |                    Pesquisa por palavras inteiras.\n",
      " |                    Regex gerado: (\\W|^)(palavras_separadas_por_pipe)(\\W|$)\n",
      " |          distancia: Quantidade de tokens antes ou depois do token. \n",
      " |                     Se 'max' (ou qualquer string), extende até o final ou o início da sentença, dependendo do contexto.\n",
      " |          lemma: Se True, lematiza palavras e contexto.\n",
      " |  \n",
      " |  hasWordInContextPrecede(self, token: spacy.tokens.token.Token, palavras: list, distancia=5, lemma: bool = False) -> bool\n",
      " |      Verifica se existe 'palavras' a uma distância de até 5 tokens antes do 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Objeto Token do spaCy\n",
      " |          palavras: Expressão que deseja encontrar. Pode ser string, lista de strings, Token ou expressão regular.\n",
      " |                    Pesquisa por palavras inteiras.\n",
      " |                    Regex gerado: (\\W|^)(palavras_separadas_por_pipe)(\\W|$)\n",
      " |          distancia: Quantidade de tokens antes ou depois do token. \n",
      " |                     Se 'max' (ou qualquer string), extende até o final ou o início da sentença, dependendo do contexto.\n",
      " |          lemma: Se True, lematiza palavras e contexto.\n",
      " |  \n",
      " |  identicalHead(self, token1, token2) -> bool\n",
      " |      Verifica se ambos os tokens possuem a mesma palavra principal (head).\n",
      " |  \n",
      " |  isEvent(self, token)\n",
      " |      Verifica se o token é um EVENT\n",
      " |  \n",
      " |  isTimex3(self, token)\n",
      " |      Verifica se o token é um TIMEX3\n",
      " |  \n",
      " |  is_dependencyType(self, tokenPai: spacy.tokens.token.Token, tokenFilho: spacy.tokens.token.Token, tipo_dep: str) -> bool\n",
      " |      Checks for type(token1=governor, token2=dependent)\n",
      " |      Verifica se a relação de dependência entre 'tokenPai' e 'tokenFilho' é 'tipo_dep'.\n",
      " |      \n",
      " |      Args:\n",
      " |          tokenPai: governor\n",
      " |          tokenFilho: dependent\n",
      " |          tipo_dep: String que representa o tipo de dependência de tokenFilho para tokenPai.\n",
      " |  \n",
      " |  lengthInBetween(self, token1: spacy.tokens.token.Token, token2: spacy.tokens.token.Token) -> int\n",
      " |      Retorna distância entre os tokens.\n",
      " |  \n",
      " |  list_to_str(self, lista, delimitador: str = ' ') -> str\n",
      " |      Converte 'lista' em string minúculas.\n",
      " |      \n",
      " |      Args:\n",
      " |          lista: Pode ser: str, list, Doc, Span, Token\n",
      " |          delimitador: separador de cada palavra na string quando 'lista' for do tipo list.\n",
      " |      \n",
      " |      Return:\n",
      " |          Se 'lista' for do tipo list, converte-a em string minúsculas separadas por 'delimitador'. \n",
      " |          Se 'lista' for do tipo Doc, Span ou Token, converte em string minúsculas.\n",
      " |          Se não, retorna string minúsculas.\n",
      " |  \n",
      " |  morph(self, token: spacy.tokens.token.Token, morph: tuple) -> bool\n",
      " |      Verifica se 'token' possue o elemento morph representado pela tupla (key, value) da análise morfológica.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Token\n",
      " |          morph: tupla (key, value), ex: ('Tense', 'Fut')\n",
      " |  \n",
      " |  pos(self, token: spacy.tokens.token.Token, pos: list) -> bool\n",
      " |      Verifica se 'token' é uma das classes gramaticais da lista 'pos'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Token\n",
      " |          pos: lista de classes gramaticais\n",
      " |  \n",
      " |  precededBy(self, token: spacy.tokens.token.Token, tipo: \"string: 'str', 'str_lemma', 'token', 'digito', 'pos', 'dep', 'morph'\", valor=None, distancia='max') -> bool\n",
      " |      Procura elementos na sentença antes do 'token', conforme o 'tipo'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: objeto Token do spaCy.\n",
      " |          tipo: string e pode ser:\n",
      " |                str      -> verifica se existe palavras especificada em valor \n",
      " |                         -> valor: str ou list; PODE SER OMITIDO.\n",
      " |                str_lemma -> verifica se existe palavras lematizadas especificada em valor \n",
      " |                          -> valor: str ou list;\n",
      " |                token    -> verifica se 'token' precede o outro token especificado em valor \n",
      " |                         -> valor: Token; PODE SER OMITIDO.\n",
      " |                digito   -> verifica se há digitos ou pos = 'NUM' -> Não tem valor;\n",
      " |                         -> Se valor for informado, ele será a distância.\n",
      " |                pos      -> verifica se há a classe gramatical especificada em valor \n",
      " |                         -> valor: list, ex: ['VERB', 'NOUM'];\n",
      " |                dep      -> verifica se há na árvore de dependencia o elemento especificado em valor \n",
      " |                         -> valor: list, ex: ['nsubj', 'nmod'];\n",
      " |                morph    -> verifica se há na análise morfológica o elemento especificado em valor. \n",
      " |                         -> valor: tuple (key, value), ex: ('Tense', 'Fut'). Só é permitido uma tupla.\n",
      " |          valor: valor do elemento que será procurado, conforme o tipo.\n",
      " |          distancia: Se inteiro, é quantidade de tokens antes de 'token' onde a pesquisa será realizada.\n",
      " |                     Se string, a pesquisa será realizada em todos os tokens que precedem 'token'.\n",
      " |  \n",
      " |  sameTense(self, token1: spacy.tokens.token.Token, token2: spacy.tokens.token.Token) -> bool\n",
      " |      Verificar se os tokens possuem o mesmo tempo verbal.\n",
      " |  \n",
      " |  search(self, palavras, frase, lemma: bool = False)\n",
      " |      Verifica se 'palavras' inteiras estão presentes em 'frase'.\n",
      " |      \n",
      " |      Args:\n",
      " |          palavras: Pode ser list, str, Token ou expressão regular.\n",
      " |                    Pesquisa por palavras inteiras.\n",
      " |                    Regex gerado: (\\W|^)(palavras_separadas_por_pipe)(\\W|$)\n",
      " |          frase: Texto onde as 'palavras' serão encontradas.\n",
      " |                 Pode ser list, str, Doc, Span e Token\n",
      " |          lemma: Se True, lematiza palavras e frase.\n",
      " |  \n",
      " |  spanContext(self, token, distancia=5, contexto=None) -> list\n",
      " |      Retorna pedaço da sentença com a quantidade de token 'distancia', conforme contexto (antes ou depois de 'token')\n",
      " |      \n",
      " |      Return: Lista de Span\n",
      " |  \n",
      " |  spanFollow(self, token, distancia=5) -> spacy.tokens.span.Span\n",
      " |      Retorna pedaço da sentença do tamanho da 'distancia' depois de 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Objeto Token.\n",
      " |          distancia: Se inteiro, é quantidade de tokens depois de 'token'.\n",
      " |                     Se string, a pesquisa será realizada em todos os tokens que vem depois de 'token'.\n",
      " |      \n",
      " |      Return: Span\n",
      " |  \n",
      " |  spanPrecede(self, token, distancia=5) -> spacy.tokens.span.Span\n",
      " |      Retorna pedaço da sentença do tamanho da 'distancia' antes de 'token'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Objeto Token.\n",
      " |          distancia: Se inteiro, é quantidade de tokens antes de 'token'.\n",
      " |                     Se string, a pesquisa será realizada em todos os tokens que vem antes de 'token'.\n",
      " |      \n",
      " |      Return: Span\n",
      " |  \n",
      " |  spanSomeMatch(self, span1: spacy.tokens.span.Span, span2: spacy.tokens.span.Span) -> bool\n",
      " |      Verifica se há interseção entre dois pedaços da sentenças.\n",
      " |      \n",
      " |      Args:\n",
      " |          span1: parte 1 da sentença.\n",
      " |          span2: parte 2 da sentenca.\n",
      " |  \n",
      " |  str_to_list(self, palavra: str) -> list\n",
      " |      Se 'palavra' for string, converte em lista unitária de string maiúsculas.\n",
      " |      Se não, converte em maíusculas.\n",
      " |  \n",
      " |  t1AfterT2(self, t1: spacy.tokens.token.Token, t2: spacy.tokens.token.Token) -> bool\n",
      " |      Returna True se t1 estiver posicionado na frase depois de t2. Senão retorna False.\n",
      " |  \n",
      " |  t1BeforeT2(self, t1: spacy.tokens.token.Token, t2: spacy.tokens.token.Token) -> bool\n",
      " |      Returna True se t1 estiver posicionado na frase antes de t2. Senão retorna False.\n",
      " |  \n",
      " |  tenseVerb(self, token: spacy.tokens.token.Token, tense: list) -> bool\n",
      " |      Verifica se 'token' possui tempo verbal 'tense'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Token\n",
      " |          tense: str ou list\n",
      " |                 tempo verbal válidos: 'FUT', 'IMP', 'PAST', 'PQP', 'PRES'\n",
      " |  \n",
      " |  tipo(self, token: spacy.tokens.token.Token, tipo: list) -> bool\n",
      " |      Verifica se 'token' é uma dos tipos de timex3 da lista 'tipo'.\n",
      " |      \n",
      " |      Args:\n",
      " |          token: Token\n",
      " |          tipo: lista de tipos de timex\n",
      " |  \n",
      " |  verbGerundio(self, token: spacy.tokens.token.Token) -> bool\n",
      " |      Verifica se é gerúndio.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RulesFunctions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d258e2-fcb9-4f61-8139-467152adcff3",
   "metadata": {},
   "source": [
    "### Pipeline spaCy para TimebankPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba74d67-9f50-47d3-b540-bc9acbf3774b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m  \u001b[0mPipeTimebankPT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Implementa pipeline do spaCy que processa anotações do corpus TimeBankPT trazendo para a estrutura do spaCy as tag EVENT e TIMEX3.\n",
       "Adicionar antes do pipe nlp.add_pipe(\"merge_entities\")\n",
       "\n",
       "Arg:\n",
       "    tb_dict: Dicionário de dados contendo dados do TimebankPT necessários para este pipeline do spaCy.\n",
       "\n",
       "Return: \n",
       "    Objeto Doc do spaCy processado contendo as tag do TimebankPT (EVENT e TIMEX3).\n",
       "    \n",
       "\u001b[1;31mInit docstring:\u001b[0m Registra novos atributos para o Doc e Token.\n",
       "\u001b[1;31mFile:\u001b[0m           e:\\backup_online\\onedrive\\documents\\dárcio online\\pós-graduação\\mestrado\\experimentos\\temporal_relation\\parse\\parsetimebankpt.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from parse.ParseTimebankPT import PipeTimebankPT\n",
    "? PipeTimebankPT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
